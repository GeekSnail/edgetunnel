# This is a basic workflow to help you get started with Actions

name: IP Workflow

# Controls when the workflow will run
on:
  schedule:
    # every Sunday, get ipupdate data, test and update to kv `proxy`, `proxy_bak`
    - cron: "0 8 * * 0"
    # everyday, get kv `proxy`, test and update the same above
    - cron: "0 22 * * *"
  # Triggers the workflow on push or pull request events but only for the "main" branch
  #push:
  #  branches: [ "main" ]
  #pull_request:
  #  branches: [ "main" ]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:
    inputs:
      downloadUpdatedIP:
        description: "download the daily updated IP data from baipiao.eu.org first before merging the IP data"
        required: false
        default: "true"
        type: choice
        options:
          - true
          - false

env:
  EVENT_NAME: ${{github.event_name}}
  CF_API_TOKEN: ${{secrets.CF_API_TOKEN}}
  CF_NAMESPACE_ID: ${{secrets.CF_NAMESPACE_ID || vars.CF_NAMESPACE_ID}}
  CF_KV_API: https://api.cloudflare.com/client/v4/accounts/${{secrets.CF_ACCOUNT_ID}}/storage/kv/namespaces/${{secrets.CF_NAMESPACE_ID || vars.CF_NAMESPACE_ID}}/values
  PING_API: https://api.globalping.io/v1/measurements
  PING_LIMIT: ${{vars.PING_COUNTRY || 3}}
  PING_COUNTRY: ${{vars.PING_COUNTRY || 'HK'}}
  HTTP_DELAY: ${{vars.HTTP_DELAY || 1000}}
  TRACE_HOST: ${{vars.TRACE_HOST || 'time.cloudflare.com'}}
  TRACE_PATH: /cdn-cgi/trace
  PROXYS: proxys
  PROXYS_BAK: proxys_bak
  PROXYS_UPDATED: proxys_updated
  PROXYS_JSON: src/proxys.json

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  update-ip:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest
    outputs:
      data: ${{ steps.put-data.outputs.data }}
    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v4

      - name: download ip zip file, unzip, merge, uniq
        if: ${{ contains(github.event.schedule, '*/2') || inputs.downloadUpdatedIPFirst == 'true' }}
        run: |
          [ -z ${{secrets.CF_ACCOUNT_ID}} ] || [ -z $CF_API_TOKEN ] || [ -z $CF_NAMESPACE_ID ] && echo "secrets and CF_NAMESPACE_ID required!" && exit 1;
          #url='https://zip.baipiao.eu.org'
          url='https://zip.cm.edu.kg/all.txt'          
          cnt=0
          while [ $cnt -lt 5 ] && ! curl --connect-timeout 10 --retry 1 "$url" -O; do
            sleep 1
            cnt=$(($cnt+1))
            echo 'retry...'
          done
          [ -s all.txt ] || (echo "Failed to download ip data from $url!" && exit 1);
          #unzip ip.zip -d ip
          #cat ip/*.txt | sort | uniq > ip.txt
          cat all.txt | grep 443 | sed 's/:.*//' | sort | uniq > ip.txt
          echo ipupdate `wc -l ip.txt` | tee $GITHUB_STEP_SUMMARY

      - name: backup original data, merge
        run: |
          for key in $PROXYS_BAK $PROXYS; do
            ret=`curl -H "Authorization:Bearer $CF_API_TOKEN" "$CF_KV_API/$key"`
            if echo "$ret"|grep error; then
              grep 'namespace not found' <<< "$ret" && exit 1 || echo "$ret"
            elif [ ! -z "$ret" ] && ! echo "$ret"|grep '443":\[\]'; then
              echo "$ret" |tr -d '{"[]}'|sed -r 's/, */\n/g'|sed -r '/^\w*:$/d'|sed -r 's/^\w*:([\d\.]*)/\1/' >> ip.txt
              if [ $key == $PROXYS ]; then
                curl -X PUT -H "Authorization:Bearer $CF_API_TOKEN" -d "$ret" "$CF_KV_API/$PROXYS_BAK"
              fi
            fi
          done
          echo `cat $PROXYS_JSON`|tr -d '["]'|sed -r 's/, */\n/g' >> ip.txt
          cat ip.txt | sort | uniq > tmp.txt
          mv tmp.txt ip.txt
          echo merge `wc -l ip.txt` | tee $GITHUB_STEP_SUMMARY

      - name: http test, filter
        run: |
          set +e
          UA="Mozilla/5.0 (Linux; Android 11; Pixel 5) AppleWebKit/537.36 Chrome/107.0.0.0 Mobile Safari/537.36"
          TRACE_URL="$TRACE_HOST$TRACE_PATH"
          OPENAI_HOST='android.chat.openai.com'; OPENAI_PATH='/public-api/mobile/server_status/v1'; 
          OPENAI_URL="$OPENAI_HOST$OPENAI_PATH"
          # ip port host path method?
          req_data(){
            local p=http; [ $2 -eq 443 ] && p=https
            local m=HEAD; [ ! -z $5 ] && m=$5
            echo '{"type":"http","target":"'$1'","locations":[{"country":"'$PING_COUNTRY'","limit":'$PING_LIMIT'}],"measurementOptions":{"port":'$2',"protocol":"'$p'","request":{"method":"'$m'","host":"'$3'","path":"'$4'"}}}'
          }
          # ret
          get_avg(){
            local n=$PING_LIMIT avg=0
            local m=`echo $1|tr -s '{,}' '\n'|grep total|cut -d ':' -f2`
            for t in $m; do 
              [ $t = null ] && n=$(($n-1)) || avg=$(($avg+$t)); 
            done
            [ $n -gt 0 ] && echo $(($avg/$n)) || echo 0
          }
          # data
          measure(){
            local url=`curl -H "content-type: application/json" -A "$UA" \
              -d "$1" -si "$PING_API"|grep location|awk '{print $2}'|tr -d '\n\r'`
            [ -z $url ] && echo 'error: no url' && exit 1
            sleep 1
            while true; do
              local r=`curl -A "$UA" -s "$url"`
              grep -q 'in-progress' <<< "$r" && sleep 1 && continue;
              break;
            done
            echo -n "$url" >&2
            echo "$r"
          }
          # ip port
          measure_http(){
            [ -z $1 ] && echo 'error: no ip' && return
            local ip=$1 port=$2
            [ -z "$port" ] && port=443
            local d=`req_data "$ip" $port "$TRACE_HOST" "$TRACE_PATH"`
            local r=`measure $d`
            local avg=0
            avg=`get_avg "$r"`
            local msg=" $ip:$port $avg"
            case "$r" in
              #*authorized\":*)
                #local d=`echo $r|tr -s '{,.}' '\n'|grep expiresAt|grep -v null|tr -s '"T' ' '|awk '{printf "%s %s\n",$3,$4}'|head -n 1`
                #[ -z "$d" ] || [ $((`date -d "$d" +%s`-`date +%s`)) -lt 86400 ]
             *cloudflare*statusCode\":200*)
                echo "$msg"
                [ $avg -gt 0 ] && [ $avg -lt $HTTP_DELAY ] && echo "$ip" >> ip$port.txt;
                ;;
              *)
                echo
                ;;
            esac
          }
          measure_openai(){
            [ -z $1 ] && echo 'error: no ip' && return
            local ip=$1 port=443
            # https://api.openai.com/compliance/cookie_requirements 
            local d=`req_data "$ip" $port "$OPENAI_HOST" "$OPENAI_PATH" GET`
            local r=`measure $d`
            local avg=0
            avg=`get_avg "$r"`
            local msg=" $ip:$port $avg"
            case "$r" in
              *status\\\":\\\"normal*statusCode\":200*)
                echo "$msg normal"
                echo "$ip" >> ipopenai.txt
                ;;
              #*disallowed\ ISP*)
              #  echo "$msg disallowed ISP"
              #	[ $avg -gt 0 ] && [ $avg -lt $HTTP_DELAY ] && echo "$ip" >> ip$port.txt
              #	;;
              #*unsupported_country*)
              #  echo "$msg unsupported_country"
              #	[ $avg -gt 0 ] && [ $avg -lt $HTTP_DELAY ] && echo "$ip" >> ip$port.txt
              #	;;
              *)
                echo "$msg"
                ;;
            esac
          }

          probe_http(){
            [ -z $1 ] && echo 'error: no ip' && return
            local ip=$1 port=$2 p=http
            [ -z "$2" ] && port=443
            [ $port -eq 443 ] && p=https
            eval `curl -I --connect-timeout 5 -so /dev/null -w 'local code=%{http_code} time=%{time_connect}' --connect-to $TRACE_HOST:$port:$ip:$port $p://$TRACE_URL`
            
            if [ "$code" = 200 ]; then
              local ms=`echo "scale=0; $time*1000/1" | bc`
              if [ $ms -gt 0 ] && [ $ms -lt $HTTP_DELAY ]; then
                echo $ip:$port $ms
                echo $ip >> ip$port.txt
              fi
            fi
          }
          probe_openai(){
            [ -z $1 ] && echo 'error: no ip' && return
            local ip=$1 port=443 p=https
            local r=`curl -A "UA" --connect-timeout 5 -s -w ' code=%{http_code} time=%{time_connect}' --connect-to $OPENAI_HOST:$port:$ip:$port $p://$OPENAI_URL`
            eval `echo $r|sed -r 's/^.*(code=.*)$/local \1/'`
            #local ms=`echo "scale=0; $time*1000/1" | bc`
            [ ! -z $code ] && [ $code != 000 ] && echo $ip:$port $r
            if [ $code = 200 ]; then
              echo $ip >> ipopenai.txt
            elif [ $code != 400 ] || echo "$r"|grep 'html'; then
              sed -i '/'$ip'/d' ip$port.txt
            fi
          }

          # while IFS= read -r ip; do
            # measure_http $ip 443
          # done < ip.txt
          # while IFS= read -r ip; do
            # measure_openai $ip
            # measure_http $ip 80
          # done < ip443.txt
          while IFS= read -r ip; do
            probe_http $ip 443
          done < ip.txt
          while IFS= read -r ip; do
            probe_openai $ip
            probe_http $ip 80
          done < ip443.txt
          echo `wc -l ip443.txt`| tee $GITHUB_STEP_SUMMARY
          echo `wc -l ip80.txt` | tee -a $GITHUB_STEP_SUMMARY
          echo `wc -l ipopenai.txt`| tee -a $GITHUB_STEP_SUMMARY

      - id: put-data
        name: update valid ip to server
        run: |
          data=
          for i in 443 80 openai; do
            [ ! -z $data ] && data=$data,
            if [ -s ip$i.txt ]; then
              data=$data\"$i\":[$(echo `sed -r 's/^(.*)$/"\1"/' ip$i.txt`|tr -s ' ' ',')]
            else
              data=$data\"$i\":[]
            fi
          done
          data={$data}
          curl -X PUT -H "Authorization:Bearer $CF_API_TOKEN" \
            -d "$data" "$CF_KV_API/$PROXYS" >> $GITHUB_STEP_SUMMARY
          curl -X PUT -H "Authorization:Bearer $CF_API_TOKEN" \
            -d "`date +%s`" "$CF_KV_API/$PROXYS_UPDATED"
          echo "data=$data" >> $GITHUB_OUTPUT

      - name: upload ip file
        uses: actions/upload-artifact@v4
        with:
          name: cfproxys
          path: |
            ip443.txt
            ip80.txt
            ipopenai.txt

  deploy:
    needs: update-ip
    uses: ./.github/workflows/update_host.yml
    with:
      proxys: ${{ needs.update-ip.outputs.data }}
    secrets: inherit

  workflow-keepalive:
    if: ${{ github.event_name == 'schedule' }}
    runs-on: ubuntu-latest
    permissions:
      actions: write
    steps:
      - uses: liskin/gh-workflow-keepalive@v1
